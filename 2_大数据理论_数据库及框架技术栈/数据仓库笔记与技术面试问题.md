

# 基础部分 面试基本情况

> ## 面试题：自我介绍

# 第一部分 大数据概念理解

## 第一节、关系型数据库

1. 什么是缓慢变化维（SCD）？如何处理？**
   - **回答要点**：维度表中某些属性会随时间变化（如客户地址）。
     - **类型1**：直接覆盖旧值（不保留历史）。
     - **类型2**：添加新行，标记生效时间（保留历史）。
     - **类型3**：添加新列记录旧值（仅保留有限历史）。
2. **什么是事务？ACID 特性是什么？**
   - **回答要点**：事务是数据库操作的原子单元。ACID 特性：
     - **原子性（Atomicity）**：事务要么全部完成，要么全部回滚。
     - **一致性（Consistency）**：事务前后数据库状态一致。
     - **隔离性（Isolation）**：并发事务互不干扰。
     - **持久性（Durability）**：事务提交后数据永久保存。
     - - - 
     - 

## 第二节、数据仓库

### 一、如何理解数据仓库

> "A Data Warehouse is a <u>**subject-oriented**</u>, <u>**integrated**</u>,  <u>**non-volatile**</u> and <u>**time-variant**</u>  collection of data , designed to support management decision-making and data analysis. support of management's decision-making process."
>
> ​								--“数据仓库之父”的比尔·恩门（Bill Inmon）
>
> 数据仓库是一个面向主题的、集成的、相对稳定的、随时间变化的数据集合，用于支持管理决策.
>

数据仓库是为了分析数据而设计的。说人话就是用于支持管理决策

数据库为了捕获、存储而设计的。

### 二、数据库和数据仓库的区别（OLTP 和OL AP）的区别？

- **OLTP** 用于支持日常业务操作，特点是高并发、低延迟、频繁更新。

- **OLAP** 用于支持数据分析和决策制定，特点是复杂查询、大规模数据聚合、历史数据分析。

  > 面试题：数据库和数据仓库的区别？
  >
  > 答：
  >
  > | **特性**     | **OLTP**                     | **OLAP**                             |
  > | :----------- | :--------------------------- | :----------------------------------- |
  > | **目标**     | 支持日常业务操作             | 支持数据分析和决策制定               |
  > | **数据量**   | 数据量较小，存储当前数据     | 数据量较大，存储历史数据             |
  > | **数据更新** | 频繁更新（增删改查操作）     | 很少更新，主要用于查询               |
  > | **数据结构** | 规范化设计（减少冗余）       | 非规范化设计（如星型模型、雪花模型） |
  > | **查询类型** | 简单的事务性查询             | 复杂的分析性查询                     |
  > | **性能要求** | 高并发、低延迟               | 高吞吐量、支持复杂计算               |
  > | **用户**     | 业务操作人员（如店员、客服） | 数据分析师、管理层                   |

  

- 

### 三、数仓理论

#### 1、传统离线数仓分层

##### 1、**ODS**（operation data store） 贴源层

贴源层是用于<u>**存放从源系统提取的原始数据**</u>。

这些数据在贴源层中<u>**不做任何处理，**</u>保持与源系统相同的结构和格式

项目：数据来源：深交所的供应商，主要有1、国家专利局数据（发明专利、实用新型和外观设计，法律上的数据），2、上市公司的基础数据和财务数据，3、国内高校科研院所基础数据，其他零零散散的一些。

##### 2、DW （data ware house）数仓层

​      1）数据细节层 DWD

​      2）数据中间层 DWM

​      3）数据服务层 DWS

##### 3、ADS（）数据应用层

**ADS层（Application Data Store）数据应用层**



> #### 面试题：为何要分层？
>
> 数据仓库分层的主要目的是<u>**实现数据的清晰管理**</u>、<u>**高效处理**</u>和<u>**灵活应用**</u>。
>
> 通过分层设计，可以明确数据的流向、提高数据质量、优化查询性能、支持多种分析场景，并提高系统的可维护性和扩展性。
>
> 例如，贴源层用于存储原始数据，数据仓库层用于整合和清洗数据，应用层用于支持业务分析和决策。
>
> 分层设计不仅降低了数据处理的复杂度，还为团队协作和数据治理提供了良好的基础
>
> 发明
>
> 

### 2、数据湖

3、数据中台、湖仓一体

4、lambda架构

数据源层

数据采集层

大数据平台层

数仓层

应用层

5、kappa架构



# 第二部分 主流框架技术栈

## 前提：现代理论基础-谷歌三篇论文

**1、Google File System（GFS）--2003年***

  HDFS的设计灵感，解决了存储方案。

- 分布式文件系统

- 采用主从架构，主节点管理元数据，分节点储存数据块。

2、**MapReduce: Simplified Data Processing on Large Clusters - 2004年**

  MapReduce成为Hadoop的核心计算框架，简化了数据处理。

3、**Bigtable: A Distributed Storage System for Structured Data - 2006年**

- 结构化数据的高效存储和访问'
- HBase'

## 第一节、Hadoop

**Hadoop** 是一个开源的<u>**分布式计算框架**</u>，专门用于存储和处理大规模数据集。它最初由 Doug Cutting 和 Mike Cafarella 开发，灵感来源于 Google 的三篇经典论文（GFS、MapReduce 和 Bigtable）。Hadoop 的核心设计目标是能够以低成本、高可靠性的方式处理海量数据。

### 1. **HDFS (Hadoop Distributed File System)**

- **功能**: HDFS 是 Hadoop 的分布式文件系统，<u>**用于存储大规模数据**</u>。

- **优点**:

  - **海量数据存储：**典型文件大小GB、TB级别，百万以上文件数量
  - **高容错性**: 数据被<u>**分割成块**</u>（默认 128MB），并在集群中<u>**多节点复制**</u>（默认 **3** 份）。
  - **高吞吐量**: 适合大规模离线批量处理
  - **构建成本低、安全可靠**

- **缺点**：

  - 不适合低延迟数据访问
  - 不适合大量小文件存储（远远小于128M)
  - 不支持并发写入
  - 不支持文件随机修改、仅支持追加写入

- **特点：**主从架构**:**

  - **NameNode**: 管理文件系统的<u>**元数据**</u>（如文件目录结构、块位置、文件属性）。

    - 备用节点
    - 心跳heartbeats,3秒检查一次dataNode的健康状态

  - **DataNode**: 存储实际数据块。

    - block副本存放策略：
      - 副本1：随机选择，优先空闲的DataNode节点
      - 副本2：放在不同的机架节点
      - 副本3：放在与第二个副本同一机架的不同节点
      - 副本N：随机选择

    ![image-20250204144358438](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250204144358438.png)



> 面试题：为什么dataNode为什么是128M？
>
> 答：块太大：寻址开销高，作业执行时间过长；
>
> ​		块太小：
>
> 



> 面试题：请简述一下HDFS读写操作流程？
>
> 答：一、写入文件操作流程：
>
> 1. **客户端发起写入请求**：
>    - 客户端调用 HDFS API（如 `FileSystem.create()`）发起文件写入请求。
> 2. **与 NameNode 通信**：
>    - 客户端向 NameNode 请求文件写入权限。
>    - NameNode 检查文件是否存在以及客户端是否有写入权限。
>    - 如果检查通过，NameNode 返回一组 DataNode 列表（用于存储数据块）。
> 3. **建立数据管道（Pipeline）**：
>    - 客户端根据 NameNode 返回的 DataNode 列表，建立一个数据写入管道。
>    - 管道通常由多个 DataNode 组成（默认 3 个副本）。
> 4. **数据分块写入**：
>    - 客户端将文件数据分成固定大小的块（默认 128MB 或 256MB）。
>    - 数据块通过管道依次写入各个 DataNode。
> 5. **确认写入成功**：
>    - 每个 DataNode 将数据写入本地磁盘，并向下一个 DataNode 发送数据。
>    - 最后一个 DataNode 确认写入成功后，依次向前传递确认信息。
>    - 客户端收到最终确认后，关闭文件写入流。
> 6. **更新元数据**：
>    - 客户端通知 NameNode 文件写入完成。
>    - NameNode 更新文件的元数据（如块的位置信息）。
>
> 二、读文件操作流程：
>
> 

### 2. **MapReduce**

- **功能**: MapReduce 是 Hadoop 的分布式计算框架，用于并行处理大规模数据集。
- **特点**:
  - **编程模型**: 将计算任务分为两个阶段：
    - **Map 阶段**: 对输入数据进行处理，生成<u>**键值对**</u>（key-value pairs）。
    - **Reduce 阶段**: 对 Map 的输出进行<u>**汇总和聚合**</u>。
  - **自动并行化**: 任务被分配到集群中的多个节点并行执行。
  - **容错性**: 如果某个节点失败，任务会自动重新分配到其他节点。

### 3. **YARN (Yet Another Resource Negotiator)**

- **功能**: YARN 是 Hadoop 的**资源管理**系统，负责集群资源的调度和管理。
- **特点**:
  - **解耦计算与资源管理**: YARN 将资源管理与任务调度分离，支持多种计算框架（如 MapReduce、Spark、Flink）。
  - **核心组件**:
    - **ResourceManager**: 全局资源管理器，负责分配集群资源。
    - **NodeManager**: 每个节点上的代理，负责管理单个节点的资源

## 第二节、Hive

### 一、定义：

- Hive 是建立在 Hadoop 之上的<u>**数据仓库工具，**</u>提供类似 SQL 的查询语言（HiveQL）。
- 主要功能是将 SQL 查询转换为 MapReduce 任务，在 Hadoop 上执行

> 面试题：**Hive 和传统数据库的区别是什么？**
>
> - **回答要点**：
>   - **存储**：Hive 数据存储在 HDFS，传统数据库用本地存储。
>   
>   - **计算**：Hive 用 MapReduce/Spark，传统数据库有专用引擎。
>   
>   - **延迟**：Hive 适合批处理，传统数据库支持实时查询。
>   
>     
>
> #### 面试题：hive和Hadoop之间的关系？
>
> 答：“Hive 和 Hadoop 是紧密相关但定位不同的技术。Hadoop 是一个分布式计算框架，提供数据存储（HDFS）和分布式计算（MapReduce）能力，适合大规模数据的存储和批处理任务。而 Hive 是建立在 Hadoop 之上的数据仓库工具，提供类似 SQL 的查询语言（HiveQL），将 SQL 查询转换为 MapReduce 任务在 Hadoop 上执行。
>
> ​	Hive 的主要优势是<u>**降低开发门槛**</u>、提高开发效率和支持复杂查询，适合数据仓库、批处理分析和复杂查询场景。
>
> ​	然而，Hive 的查询性能依赖于底层的 MapReduce 引擎，延迟较高，不适合实时查询。因此，Hive 和 Hadoop 是互补的关系，Hive 依赖于 Hadoop 提供的基础设施，同时简化了 Hadoop 的使用。“

**Hive 的分区和分桶有什么区别？**

- **分区（Partition）**：按目录划分数据（如 `dt=20231001`），加速按分区过滤的查询。
- **分桶（Bucket）**：按哈希值将数据分散到固定数量的文件中，优化 JOIN 和采样效率



## 第三节、spark

### 一、定义与理解

分布式计算框架

Spark Core API

Spark SQL

Struct Streaming

Spark ML lib

### 二、运行模式

|                             | 适用场景                                              | **特点**                                                     |
| --------------------------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| 本地Local模式               | 开发、测试和调试                                      | 简单易用，无需集群环境。                                     |
| Standalone 模式（独立模式） | 中小规模集群，无需依赖外部集群管理器。                | 需要手动启动 Spark 集群（Master 和 Worker 节点）。 支持高可用性（HA）模式，可以通过 ZooKeeper 实现 Master 的故障恢复。 |
| **YARN 模式**               | 已经部署 Hadoop 的大数据集群                          | 在 Hadoop YARN（Yet Another Resource Negotiator）上运行 Spark，YARN 负责资源管理和任务调度。 |
| Mesos                       | 需要与其他框架（如 Hadoop、Kafka 等）共享资源的集群。 | 支持细粒度和粗粒度的资源调度。 适合多框架共享资源的场景。    |
| **Kubernetes 模式**         | 基于容器的云原生环境。                                | 支持动态资源分配和容器化部署。 适合云原生架构和微服务环境。  |





弹性分布式数据集



面试题

- Spark与Hadoop的区别？
- RDD、DataFrame和Dataset的区别？
- 如何优化Spark作业？
- spark为什么比mp快？
  - MR计算是基于磁盘的，Spark计算是基于内存的。
- 什么是宽依赖和窄依赖？
- 如何解决Spark中的数据倾斜问题？
- Spark如何实现容错？

## 四、flink



# 第三部分 SQL

经典题型：

hivesql

sparksql

# 第四部分 python



# 第五部分 算法