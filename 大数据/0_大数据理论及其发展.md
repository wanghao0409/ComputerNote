

# 第一部分 关系型数据库



# 第二部分 传统数据仓库

## 一、如何理解数据仓库

> "A Data Warehouse is a <u>subject-oriented</u>, <u>**integrated**</u>,  <u>**non-volatile**</u> and <u>**time-variant**</u>  collection of data , designed to support management decision-making and data analysis. support of management's decision-making process."
>
> ​								--“数据仓库之父”的比尔·恩门（Bill Inmon）
>
> 数据仓库是一个面向主题的、集成的、相对稳定的、随时间变化的数据集合，用于支持管理决策.
>****

数据仓库是为了分析数据而设计的。说人话就是用于支持管理决策

数据库为了捕获、存储而设计的。

## 二、数据库和数据仓库的区别（OLTP 和OL AP）的区别？

- **OLTP** 用于支持日常业务操作，特点是高并发、低延迟、频繁更新。

- **OLAP** 用于支持数据分析和决策制定，特点是复杂查询、大规模数据聚合、历史数据分析。

  > 面试题：数据库和数据仓库的区别？
  >
  > 答：
  >
  > | **特性**     | **OLTP**                     | **OLAP**                             |
  > | :----------- | :--------------------------- | :----------------------------------- |
  > | **目标**     | 支持日常业务操作             | 支持数据分析和决策制定               |
  > | **数据量**   | 数据量较小，存储当前数据     | 数据量较大，存储历史数据             |
  > | **数据更新** | 频繁更新（增删改查操作）     | 很少更新，主要用于查询               |
  > | **数据结构** | 规范化设计（减少冗余）       | 非规范化设计（如星型模型、雪花模型） |
  > | **查询类型** | 简单的事务性查询             | 复杂的分析性查询                     |
  > | **性能要求** | 高并发、低延迟               | 高吞吐量、支持复杂计算               |
  > | **用户**     | 业务操作人员（如店员、客服） | 数据分析师、管理层                   |

  

  ## 

## 三、大数据存储架构数仓理论

#### 1、传统离线数仓分层

##### 1、**ODS**（operation data store） 贴源层

贴源层是用于<u>**存放从源系统提取的原始数据**</u>。

这些数据在贴源层中<u>**不做任何处理，**</u>保持与源系统相同的结构和格式

项目：数据来源：深交所的供应商，主要有1、国家专利局数据（发明专利、实用新型和外观设计，法律上的数据），2、上市公司的基础数据和财务数据，3、国内高校科研院所基础数据，其他零零散散的一些。

##### 2、DW （data ware house）数仓层

​      1）数据细节层 DWD

​      2）数据中间层 DWM

​      3）数据服务层 DWS

##### 3、ADS（）数据应用层

**ADS层（Application Data Store）数据应用层**



> #### 面试题：为何要分层？
>
> 数据仓库分层的主要目的是<u>**实现数据的清晰管理**</u>、<u>**高效处理**</u>和<u>**灵活应用**</u>。
>
> 通过分层设计，可以明确数据的流向、提高数据质量、优化查询性能、支持多种分析场景，并提高系统的可维护性和扩展性。
>
> 例如，贴源层用于存储原始数据，数据仓库层用于整合和清洗数据，应用层用于支持业务分析和决策。
>
> 分层设计不仅降低了数据处理的复杂度，还为团队协作和数据治理提供了良好的基础
>
> 发明
>
> 

### 2、数据湖

数据湖是一个**存储大规模、多样化数据的组织方法**，可以存储`结构化`、`非结构化`和`半结构化`的数据，是一个大型、灵活的数据存储仓库，可以将企业的所有数据源整合起来

结构化数据：结构化数据是指可以使用关系型数据库表示和存储的数据，通常以二维表的形式呈现。结构化数据具有以下特点：


半结构化数据：半结构化数据是结构化数据的一种形式，它不完全符合关系型数据的规范。半结构化数据具有以下特点：

非结构化数据：非结构化数据是指没有固定结构和格式的数据，通常无法以关系型数据库的形式进行存储和表示。非结构化数据具有以下特点：

综上所述，结构化数据是具有固定结构和规律排列的数据，半结构化数据是介于结构化数据和非结构化数据之间的数据形式，而非结构化数据则是没有明确结构和格式的数据。这些不同类型的数据在分析和处理时需要采用不同的方法和工具来处理和管理。

### 3、数据中台、湖仓一体

湖仓一体
湖仓一体是一个全新的开放式数据架构，它将数据湖和数据仓库的优势组合在一起，
提供了数据湖的灵活性和可扩展性以及数据仓库的数据管理功能。
这个架构是在数据湖较低成本的数据存储基础设施上构建的，
它不仅保留了数据湖的特点，如存储非结构化数据和半结构化数据，
还可以支持事务、数据治理和数据模型化等功能，这些特点是数据仓库所具备的。









# 第三部分 萌芽与奠基期 (2000年代初期 - 2010年以前)

## 前提：现代大数据理论基础-谷歌三篇论文

### **1、Google File System（GFS）--2003年**

  HDFS的设计灵感，解决了存储方案。

- 分布式文件系统

- 采用主从架构，主节点管理元数据，分节点储存数据块。

### 2、**MapReduce: Simplified Data Processing on Large Clusters - 2004年**

  MapReduce成为Hadoop的核心计算框架，简化了数据处理。

3、**Bigtable: A Distributed Storage System for Structured Data - 2006年**

- 结构化数据的高效存储和访问'
- HBase'

## 第一节、Hadoop

**Hadoop** 是一个开源的<u>**分布式计算框架**</u>，专门用于存储和处理大规模数据集。它最初由 Doug Cutting 和 Mike Cafarella 开发，灵感来源于 Google 的三篇经典论文（GFS、MapReduce 和 Bigtable）。Hadoop 的核心设计目标是能够以低成本、高可靠性的方式处理海量数据。

### 1. **HDFS (Hadoop Distributed File System)**

- **功能**: HDFS 是 Hadoop 的分布式文件系统，<u>**用于存储大规模数据**</u>。

- **优点**:

  - **海量数据存储：**典型文件大小GB、TB级别，百万以上文件数量
  - **高容错性**: 数据被<u>**分割成块**</u>（默认 128MB），并在集群中<u>**多节点复制**</u>（默认 **3** 份）。
  - **高吞吐量**: 适合大规模离线批量处理
  - **构建成本低、安全可靠**

- **缺点**：

  - 不适合低延迟数据访问
  - 不适合大量小文件存储（远远小于128M)
  - 不支持并发写入
  - 不支持文件随机修改、仅支持追加写入

- **特点：**主从架构**:**

  - **NameNode**: 管理文件系统的<u>**元数据**</u>（如文件目录结构、块位置、文件属性）。

    - 备用节点
    - 心跳heartbeats,3秒检查一次dataNode的健康状态

  - **DataNode**: 存储实际数据块。

    - block副本存放策略：
      - 副本1：随机选择，优先空闲的DataNode节点
      - 副本2：放在不同的机架节点
      - 副本3：放在与第二个副本同一机架的不同节点
      - 副本N：随机选择

    ![image-20250204144358438](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250204144358438.png)



> 面试题：为什么dataNode为什么是128M？
>
> 答：块太大：寻址开销高，作业执行时间过长；
>
> ​		块太小：
>
> 



> 面试题：请简述一下HDFS读写操作流程？
>
> 答：一、写入文件操作流程：
>
> 1. **客户端发起写入请求**：
>    - 客户端调用 HDFS API（如 `FileSystem.create()`）发起文件写入请求。
> 2. **与 NameNode 通信**：
>    - 客户端向 NameNode 请求文件写入权限。
>    - NameNode 检查文件是否存在以及客户端是否有写入权限。
>    - 如果检查通过，NameNode 返回一组 DataNode 列表（用于存储数据块）。
> 3. **建立数据管道（Pipeline）**：
>    - 客户端根据 NameNode 返回的 DataNode 列表，建立一个数据写入管道。
>    - 管道通常由多个 DataNode 组成（默认 3 个副本）。
> 4. **数据分块写入**：
>    - 客户端将文件数据分成固定大小的块（默认 128MB 或 256MB）。
>    - 数据块通过管道依次写入各个 DataNode。
> 5. **确认写入成功**：
>    - 每个 DataNode 将数据写入本地磁盘，并向下一个 DataNode 发送数据。
>    - 最后一个 DataNode 确认写入成功后，依次向前传递确认信息。
>    - 客户端收到最终确认后，关闭文件写入流。
> 6. **更新元数据**：
>    - 客户端通知 NameNode 文件写入完成。
>    - NameNode 更新文件的元数据（如块的位置信息）。
>
> 二、读文件操作流程：
>
> 

### 2. **MapReduce**

- **功能**: MapReduce 是 Hadoop 的分布式计算框架，用于并行处理大规模数据集。
- **特点**:
  - **编程模型**: 将计算任务分为两个阶段：
    - **Map 阶段**: 对输入数据进行处理，生成<u>**键值对**</u>（key-value pairs）。
    - **Reduce 阶段**: 对 Map 的输出进行<u>**汇总和聚合**</u>。
  - **自动并行化**: 任务被分配到集群中的多个节点并行执行。
  - **容错性**: 如果某个节点失败，任务会自动重新分配到其他节点。

### 3. **YARN (Yet Another Resource Negotiator)**

- **功能**: YARN 是 Hadoop 的**资源管理**系统，负责集群资源的调度和管理。
- **特点**:
  - **解耦计算与资源管理**: YARN 将资源管理与任务调度分离，支持多种计算框架（如 MapReduce、Spark、Flink）。
  - **核心组件**:
    - **ResourceManager**: 全局资源管理器，负责分配集群资源。
    - **NodeManager**: 每个节点上的代理，负责管理单个节点的资源

## 第二节、Hive

### 一、定义：

- Hive 是建立在 Hadoop 之上的<u>**数据仓库工具，**</u>提供类似 SQL 的查询语言（HiveQL）。
- 主要功能是将 SQL 查询转换为 MapReduce 任务，在 Hadoop 上执行

> 面试题：**Hive 和传统数据库的区别是什么？**
>
> - **回答要点**：
>   - **存储**：Hive 数据存储在 HDFS，传统数据库用本地存储。
>   
>   - **计算**：Hive 用 MapReduce/Spark，传统数据库有专用引擎。
>   
>   - **延迟**：Hive 适合批处理，传统数据库支持实时查询。
>   
>     
>
> #### 面试题：hive和Hadoop之间的关系？
>
> 答：“Hive 和 Hadoop 是紧密相关但定位不同的技术。Hadoop 是一个分布式计算框架，提供数据存储（HDFS）和分布式计算（MapReduce）能力，适合大规模数据的存储和批处理任务。而 Hive 是建立在 Hadoop 之上的数据仓库工具，提供类似 SQL 的查询语言（HiveQL），将 SQL 查询转换为 MapReduce 任务在 Hadoop 上执行。
>
> ​	Hive 的主要优势是<u>**降低开发门槛**</u>、提高开发效率和支持复杂查询，适合数据仓库、批处理分析和复杂查询场景。
>
> ​	然而，Hive 的查询性能依赖于底层的 MapReduce 引擎，延迟较高，不适合实时查询。因此，Hive 和 Hadoop 是互补的关系，Hive 依赖于 Hadoop 提供的基础设施，同时简化了 Hadoop 的使用。“

**Hive 的分区和分桶有什么区别？**

- **分区（Partition）**：按目录划分数据（如 `dt=20231001`），加速按分区过滤的查询。
- **分桶（Bucket）**：按哈希值将数据分散到固定数量的文件中，优化 JOIN 和采样效率



# 第四部分 生态爆发与批处理成熟期 (2010年 - 2014年左右)

这个阶段的**核心矛盾**是：原始的MapReduce编程复杂、效率低下（中间结果写磁盘，IO开销大），无法满足更丰富的应用场景（如交互式查询）。

**1. 核心思想：**
“**一个架构，多种专用工具**”。Hadoop稳定后，大家不再满足于只有MapReduce一种计算模型。整个社区围绕HDFS，构建了一个庞大的“**Hadoop生态系统**”，针对不同场景出现了专用工具。

**2. 主要技术与代表：**

- **资源管理**：**YARN (Yet Another Resource Negotiator)** 从Hadoop中解耦出来，成为集群资源的统一管理和调度器。从此，各种计算框架（如Spark）可以共享同一个HDFS集群资源，大大提升了资源利用率和集群管理效率。
- **SQL-on-Hadoop**：为了让熟悉SQL的分析师和用户也能使用Hadoop，出现了**Hive**。它可以将SQL查询自动转换为MapReduce任务执行，极大地降低了使用门槛。后续还有**Impala**, **Presto**等更快的交互式查询引擎。
- **NoSQL数据库**：**HBase**（基于HDFS的列式存储）、**Cassandra**等数据库蓬勃发展，满足了高吞吐、低延迟的读写需求。
- **新一代计算框架**：**Spark** 闪亮登场。其核心创新在于**基于内存的计算**（RDD弹性分布式数据集），将多个计算步骤的中间结果保存在内存中，避免了MapReduce频繁读写磁盘的弊端，性能比MapReduce提升了10-100倍。Spark统一了批处理、流处理、机器学习等多种场景。

**阶段特征：** 生态系统极度繁荣，解决了**“不好用”**和**“慢”**的问题。批处理性能大幅提升，并出现了交互式查询能力。但数据处理的**实时性**仍然不足。

# 第五部分：流处理与Lambda/Kappa架构 (2014年 - 2018年左右)

这个阶段的**核心矛盾**是：企业需要更及时的数据洞察，批处理“T+1”的模式无法满足实时推荐、实时风控、实时监控等场景的需求。

**1. 核心思想：**
“**既要批处理，也要流处理**”。流处理（Stream Processing）技术成为焦点，追求数据的低延迟（秒级、毫秒级）处理。

**2. 架构演进：**

## **Lambda架构**

- 为了解决批处理（高延迟高准确）和流处理（低延迟不精确）的优缺点，Nathan Marz提出了Lambda架构。

- 它包含三条流水线：

- **批处理层（Batch Layer）**批处理层存储管理主数据集（不可变的数据集）和预先批处理计算好的视图。

- **速度层（Speed Layer）**  速度处理层会实时处理新来的大数据。

- **服务层（Serving Layer）**。 所有在批处理层和速度层处理完的结果都输出存储在服务层中，服务层通过返回预先计算的数据视图或从速度层处理构建好数据视图来响应查询

  架构复杂，需要维护两套代码。

![image-20251021092055716](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20251021092055716.png)





## **Kappa架构**

- 由Jay Kreps提出，作为对Lambda架构的简化。其核心思想是：**只用一套流处理系统**，但要具备重放历史数据的能力。通过永久存储日志（如Kafka），需要全量计算时，就重新消费所有历史数据；需要实时计算时，就消费实时数据。**Apache Flink** 因其强大的状态管理和 Exactly-Once 语义，成为实现Kappa架构的理想选择。
- **流式处理层**
- **服务层**
- ![image-20251021092519679](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20251021092519679.png)

**3. 主要技术与代表：**

- **流处理引擎**：**Storm**（早期）、**Spark Streaming**（微批处理）、**Flink**（真正的流处理，低延迟高一致性，成为后期主流）。
- **消息队列**：**Kafka** 从LinkedLin开源后，成为连接各类数据源和数据处理引擎的“**神经系统**”，解决了数据流的可靠传输和缓冲问题。



## 流批一体



## Dataflow 模型全流程



## 实时数仓

**实时数仓通常具有四个组件：数据收集层、数据存储层、实时计算层和实时应用层。**

**这些组件协同工作，以便在事件发生后立即或短时间内支持事件数据的处理和分析。所有数据处理阶段（数据摄取、丰富、分析、基于 AI/ML 的分析）都是连续的，具有最小延迟，并且能够实现实时报告和即席分析。**

**阶段特征：** 流处理技术成熟，**实时数据处理**成为企业大数据平台的标配。架构从复杂的Lambda向更简洁的Kappa演进。





# 第六部分：云原生、一体化与智能化 (2018年至今)

这个阶段的**核心矛盾**是：自建大数据平台技术栈复杂、运维成本高昂，企业希望更专注于数据价值本身而非底层技术。同时，AI的爆发对数据处理平台提出了更高要求。

**1. 核心思想：**
“**数据智能**”与“**数据普惠**”。技术发展的目标是让数据平台更智能、更易用、更省心。

**2. 主要趋势与技术：**

- **云原生（Cloud-Native）**：大数据基础设施全面向云上迁移。云厂商提供了**Snowflake**, **BigQuery**, **Redshift**等完全托管的云数据仓库，以及**EMR**, **Databricks**等托管Spark/Flink服务。用户无需关心集群运维，按需付费，实现了极致的弹性伸缩。
- **数据湖仓一体（Lakehouse）**：结合数据湖（低成本存储任意格式数据）和数据仓（高性能SQL和事务支持）的优势。**Delta Lake**, **Apache Iceberg**, **Hudi** 等表格式（Table Format）的出现，使得在数据湖（如S3）上构建具备ACID事务、模式演化、高效upsert能力的“数据湖仓”成为可能，成为新一代数据架构的主流方向。
- **AI与数据平台融合**：大数据平台从“处理数据”向“生产智能”演进。**MLflow** 等机器学习生命周期管理工具与数据平台紧密集成。大数据平台成为训练和部署AI模型的基础。
- **DataOps与可观测性**：借鉴DevOps思想，强调数据流程的自动化、协作化和可观测性，注重数据质量、血缘追踪和治理。

**阶段特征：** 技术趋于融合和一体化，底层基础设施**托管化、服务化**，用户焦点从“技术运维”彻底转向“**数据价值挖掘**”和“**数据驱动决策**”。







# 第一部分 大数据概念理解

## 第一节、关系型数据库

1. 什么是缓慢变化维（SCD）？如何处理？**
   - **回答要点**：维度表中某些属性会随时间变化（如客户地址）。
     - **类型1**：直接覆盖旧值（不保留历史）。
     - **类型2**：添加新行，标记生效时间（保留历史）。
     - **类型3**：添加新列记录旧值（仅保留有限历史）。
2. **什么是事务？ACID 特性是什么？**
   - **回答要点**：事务是数据库操作的原子单元。ACID 特性：
     - **原子性（Atomicity）**：事务要么全部完成，要么全部回滚。
     - **一致性（Consistency）**：事务前后数据库状态一致。
     - **隔离性（Isolation）**：并发事务互不干扰。
     - **持久性（Durability）**：事务提交后数据永久保存。
     - - - 
     - 

## 第二节、数据仓库

### 一、如何理解数据仓库

> "A Data Warehouse is a <u>**subject-oriented**</u>, <u>**integrated**</u>,  <u>**non-volatile**</u> and <u>**time-variant**</u>  collection of data , designed to support management decision-making and data analysis. support of management's decision-making process."
>
> ​								--“数据仓库之父”的比尔·恩门（Bill Inmon）
>
> 数据仓库是一个面向主题的、集成的、相对稳定的、随时间变化的数据集合，用于支持管理决策.

数据仓库是为了分析数据而设计的。说人话就是用于支持管理决策

数据库为了捕获、存储而设计的。

### 二、数据库和数据仓库的区别（OLTP 和OL AP）的区别？

- **OLTP** 用于支持日常业务操作，特点是高并发、低延迟、频繁更新。

- **OLAP** 用于支持数据分析和决策制定，特点是复杂查询、大规模数据聚合、历史数据分析。

  > 面试题：数据库和数据仓库的区别？
  >
  > 答：
  >
  > | **特性**     | **OLTP**                     | **OLAP**                             |
  > | :----------- | :--------------------------- | :----------------------------------- |
  > | **目标**     | 支持日常业务操作             | 支持数据分析和决策制定               |
  > | **数据量**   | 数据量较小，存储当前数据     | 数据量较大，存储历史数据             |
  > | **数据更新** | 频繁更新（增删改查操作）     | 很少更新，主要用于查询               |
  > | **数据结构** | 规范化设计（减少冗余）       | 非规范化设计（如星型模型、雪花模型） |
  > | **查询类型** | 简单的事务性查询             | 复杂的分析性查询                     |
  > | **性能要求** | 高并发、低延迟               | 高吞吐量、支持复杂计算               |
  > | **用户**     | 业务操作人员（如店员、客服） | 数据分析师、管理层                   |

  

- 

### 三、数仓理论

#### 1、传统离线数仓分层

##### 1、**ODS**（operation data store） 贴源层

贴源层是用于<u>**存放从源系统提取的原始数据**</u>。

这些数据在贴源层中<u>**不做任何处理，**</u>保持与源系统相同的结构和格式

项目：数据来源：深交所的供应商，主要有1、国家专利局数据（发明专利、实用新型和外观设计，法律上的数据），2、上市公司的基础数据和财务数据，3、国内高校科研院所基础数据，其他零零散散的一些。

##### 2、DW （data ware house）数仓层

​      1）数据细节层 DWD

​      2）数据中间层 DWM

​      3）数据服务层 DWS

##### 3、ADS（）数据应用层

**ADS层（Application Data Store）数据应用层**



> #### 面试题：为何要分层？
>
> 数据仓库分层的主要目的是<u>**实现数据的清晰管理**</u>、<u>**高效处理**</u>和<u>**灵活应用**</u>。
>
> 通过分层设计，可以明确数据的流向、提高数据质量、优化查询性能、支持多种分析场景，并提高系统的可维护性和扩展性。
>
> 例如，贴源层用于存储原始数据，数据仓库层用于整合和清洗数据，应用层用于支持业务分析和决策。
>
> 分层设计不仅降低了数据处理的复杂度，还为团队协作和数据治理提供了良好的基础
>
> 发明
>
> 

